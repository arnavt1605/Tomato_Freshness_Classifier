{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "DenseNet121_Kfold"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 12648946,
          "sourceType": "datasetVersion",
          "datasetId": 7993554
        }
      ],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "HYbopbqpoviE"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "arnav1605_tomato_data_path = kagglehub.dataset_download('arnav1605/tomato-data')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "r-BYsk38oviK"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "from torchmetrics.classification import Accuracy\n",
        "import torchmetrics\n",
        "import torchvision.models as models\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "XxqtBRJ2-3Tg",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-02T07:10:03.542378Z",
          "iopub.execute_input": "2025-08-02T07:10:03.542685Z",
          "iopub.status.idle": "2025-08-02T07:10:03.548114Z",
          "shell.execute_reply.started": "2025-08-02T07:10:03.542663Z",
          "shell.execute_reply": "2025-08-02T07:10:03.547096Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(),  #Removed RandomCrop(32) as it resized the image back\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])   #pretrained ImageNet values\n",
        "])\n",
        "\n",
        "test_transform= transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "CsgVPh7KBd72",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-02T07:10:03.549589Z",
          "iopub.execute_input": "2025-08-02T07:10:03.55007Z",
          "iopub.status.idle": "2025-08-02T07:10:03.568241Z",
          "shell.execute_reply.started": "2025-08-02T07:10:03.550045Z",
          "shell.execute_reply": "2025-08-02T07:10:03.56744Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "path= \"/kaggle/input/tomato-data/data/Training_set\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-02T07:10:03.568957Z",
          "iopub.execute_input": "2025-08-02T07:10:03.569164Z",
          "iopub.status.idle": "2025-08-02T07:10:03.584573Z",
          "shell.execute_reply.started": "2025-08-02T07:10:03.56915Z",
          "shell.execute_reply": "2025-08-02T07:10:03.584045Z"
        },
        "id": "G78bxgV4oviO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "full_dataset = datasets.ImageFolder(root=path, transform=train_transform)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-02T07:10:03.586171Z",
          "iopub.execute_input": "2025-08-02T07:10:03.586766Z",
          "iopub.status.idle": "2025-08-02T07:10:08.708211Z",
          "shell.execute_reply.started": "2025-08-02T07:10:03.58674Z",
          "shell.execute_reply": "2025-08-02T07:10:08.707562Z"
        },
        "id": "3J3-mn7HoviP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
        "num_features = model.classifier.in_features\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(num_features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(512, 10)\n",
        ")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "vNMuVBv7L8FC",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-02T07:10:08.708872Z",
          "iopub.execute_input": "2025-08-02T07:10:08.709107Z",
          "iopub.status.idle": "2025-08-02T07:10:08.940581Z",
          "shell.execute_reply.started": "2025-08-02T07:10:08.709091Z",
          "shell.execute_reply": "2025-08-02T07:10:08.939774Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_function, optimizer):\n",
        "  model.train()\n",
        "  total_loss= 0\n",
        "\n",
        "  for batch, (image, label) in enumerate(dataloader):\n",
        "    image= image.to(device)\n",
        "    label= label.to(device)\n",
        "\n",
        "    prediction= model(image)\n",
        "    loss= loss_function(prediction, label)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    total_loss+= loss\n",
        "\n",
        "  avg_loss= total_loss / len(dataloader)\n",
        "  print(f\"Training Average Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "id": "IPDYKl7HMAwp",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-02T07:10:08.941461Z",
          "iopub.execute_input": "2025-08-02T07:10:08.941689Z",
          "iopub.status.idle": "2025-08-02T07:10:08.946551Z",
          "shell.execute_reply.started": "2025-08-02T07:10:08.941672Z",
          "shell.execute_reply": "2025-08-02T07:10:08.945756Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "val_accuracy = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
        "\n",
        "def validate(dataloader, model, loss_function):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    val_accuracy.reset()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, label in dataloader:\n",
        "            image = image.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            pred = model(image)\n",
        "            loss = loss_function(pred, label)\n",
        "            total_loss += loss\n",
        "\n",
        "            val_accuracy.update(pred, label)\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    accuracy = val_accuracy.compute() * 100  # Convert to %\n",
        "\n",
        "    print(f\"Validation Loss: {avg_loss:.4f}, Validation Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "m6Vazx2GMo30",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-02T07:10:08.947414Z",
          "iopub.execute_input": "2025-08-02T07:10:08.947684Z",
          "iopub.status.idle": "2025-08-02T07:10:08.966484Z",
          "shell.execute_reply.started": "2025-08-02T07:10:08.947658Z",
          "shell.execute_reply": "2025-08-02T07:10:08.96576Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
        "\n",
        "def test(dataloader, model, loss_function):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    test_accuracy.reset()   #Reset metric state for each epoch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, label in dataloader:\n",
        "            image = image.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            pred = model(image)\n",
        "            loss = loss_function(pred, label)\n",
        "            total_loss += loss\n",
        "\n",
        "            test_accuracy.update(pred, label)\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    accuracy = test_accuracy.compute() * 100  # Convert to %\n",
        "\n",
        "    print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "OHSaFlFoMqsZ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-02T07:10:08.967363Z",
          "iopub.execute_input": "2025-08-02T07:10:08.967562Z",
          "iopub.status.idle": "2025-08-02T07:10:08.984595Z",
          "shell.execute_reply.started": "2025-08-02T07:10:08.967544Z",
          "shell.execute_reply": "2025-08-02T07:10:08.984043Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "k_folds = 5\n",
        "epochs = 50\n",
        "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(full_dataset)):\n",
        "    print(f\"\\n---------Fold {fold + 1}-----------\")\n",
        "\n",
        "    # Create data subsets and loaders\n",
        "    train_subset = Subset(full_dataset, train_idx)\n",
        "    val_subset = Subset(full_dataset, val_idx)\n",
        "\n",
        "    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_subset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, verbose=True)\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "        train(train_loader, model, loss_function, optimizer)\n",
        "        val_acc = validate(val_loader, model, loss_function)\n",
        "        scheduler.step(val_acc)\n",
        "\n",
        "        # Saving best model per fold\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), f\"best_model_fold{fold+1}.pth\")\n",
        "\n",
        "    print(f\"\\nBest Validation Accuracy in Fold {fold + 1}: {best_val_acc:.2f}%\")\n",
        "    print(\"---------------------------------------------------------------\\n\")\n"
      ],
      "metadata": {
        "id": "EXLRpD6EMsrk",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}