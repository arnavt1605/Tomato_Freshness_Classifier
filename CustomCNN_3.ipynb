{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOWLZXTqxy+PbFfWC/E9aT+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchmetrics.classification import Accuracy\n",
        "import torchmetrics\n",
        "\n",
        "import torchvision.models as models\n",
        "\n",
        "device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "XxqtBRJ2-3Tg"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNHhtBgaMIjn",
        "outputId": "6236b54c-5585-4083-b4d5-208165927a4b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (1.8.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.6.0+cu124)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (0.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"tomato_data.zip\", 'r') as zip:\n",
        "  zip.extractall(\"tomato_data\")"
      ],
      "metadata": {
        "id": "WhRLL8C6_R-Q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path= '/content/tomato_data'"
      ],
      "metadata": {
        "id": "BdZ0h5H-_7p2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(),  #Removed RandomCrop(32) as it resized the image back\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))   #pretrained ImageNet values\n",
        "])\n",
        "\n",
        "test_transform= transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "CsgVPh7KBd72"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path= '/content/tomato_data/data/Training_set'\n",
        "test_path= '/content/tomato_data/data/Testing_set'\n",
        "\n",
        "train_data= datasets.ImageFolder(root=train_path, transform= train_transform)\n",
        "test_set= datasets.ImageFolder(root=test_path, transform= test_transform)\n",
        "\n",
        "for (img, label) in train_data:\n",
        "  print(img.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCkQhXOXEGTz",
        "outputId": "157def8e-70bf-4e09-eebf-6be70a31f95d"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.85 * len(train_data))\n",
        "val_size   = len(train_data) - train_size\n",
        "\n",
        "train_set, val_set = random_split(train_data, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n"
      ],
      "metadata": {
        "id": "iv81PHojF6ls"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "val_loader   = DataLoader(val_set, batch_size=64, shuffle=False)\n",
        "test_loader  = DataLoader(test_set,  batch_size=64, shuffle=False)\n",
        "\n",
        "\n",
        "for (img, label) in train_loader:\n",
        "  print(img.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFHlyPNlJYVC",
        "outputId": "3b30a399-4e7c-4e3e-a256-19b481e9329e"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            # Block 1\n",
        "            nn.Conv2d(3, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),  # 64x64x64\n",
        "\n",
        "            # Block 2\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),  # 128x32x32\n",
        "\n",
        "            # Block 3\n",
        "            nn.Conv2d(128, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),  # 256x16x16\n",
        "\n",
        "            # Block 4\n",
        "            nn.Conv2d(256, 512, 3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, 3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))  # 512x1x1\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "vNMuVBv7L8FC"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= CNN().to(device)"
      ],
      "metadata": {
        "id": "iTO7r-u8mvhD"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loss_function= nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "TYOay03vL9yV"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer= torch.optim.Adam(model.parameters(), lr= 0.001)\n",
        "\n",
        "scheduler= torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode= \"max\", factor= 0.5, patience= 3)\n",
        ""
      ],
      "metadata": {
        "id": "CJ6bU5WnL_JT"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_function, optimizer):\n",
        "  model.train()\n",
        "  total_loss= 0\n",
        "\n",
        "  for batch, (image, label) in enumerate(dataloader):\n",
        "    image= image.to(device)\n",
        "    label= label.to(device)\n",
        "\n",
        "    prediction= model(image)\n",
        "    loss= loss_function(prediction, label)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    total_loss+= loss\n",
        "\n",
        "  avg_loss= total_loss / len(dataloader)\n",
        "  print(f\"Training Average Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "id": "IPDYKl7HMAwp"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_accuracy = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
        "\n",
        "def validate(dataloader, model, loss_function):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    val_accuracy.reset()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, label in dataloader:\n",
        "            image = image.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            pred = model(image)\n",
        "            loss = loss_function(pred, label)\n",
        "            total_loss += loss\n",
        "\n",
        "            val_accuracy.update(pred, label)\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    accuracy = val_accuracy.compute() * 100  # Convert to %\n",
        "\n",
        "    print(f\"Validation Loss: {avg_loss:.4f}, Validation Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    return accuracy\n",
        ""
      ],
      "metadata": {
        "id": "m6Vazx2GMo30"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
        "\n",
        "def test(dataloader, model, loss_function):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    test_accuracy.reset()   #Reset metric state for each epoch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, label in dataloader:\n",
        "            image = image.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            pred = model(image)\n",
        "            loss = loss_function(pred, label)\n",
        "            total_loss += loss\n",
        "\n",
        "            test_accuracy.update(pred, label)\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    accuracy = test_accuracy.compute() * 100  # Convert to %\n",
        "\n",
        "    print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "OHSaFlFoMqsZ"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 40\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "    train(train_loader, model, loss_function, optimizer)\n",
        "    val_acc = validate(val_loader, model, loss_function)\n",
        "    scheduler.step(val_acc)\n",
        "print(\"\\n\")\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"\\n\")\n",
        "test(test_loader, model, loss_function)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXLRpD6EMsrk",
        "outputId": "6a2089a9-a0ad-44ed-aab8-b6b0c4917534"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/40\n",
            "Training Average Loss: 0.9369\n",
            "Validation Loss: 1.1171, Validation Accuracy: 56.18%\n",
            "\n",
            "Epoch 2/40\n",
            "Training Average Loss: 0.9855\n",
            "Validation Loss: 1.1131, Validation Accuracy: 56.83%\n",
            "\n",
            "Epoch 3/40\n",
            "Training Average Loss: 0.9526\n",
            "Validation Loss: 1.1077, Validation Accuracy: 58.26%\n",
            "\n",
            "Epoch 4/40\n",
            "Training Average Loss: 0.9475\n",
            "Validation Loss: 1.1150, Validation Accuracy: 57.09%\n",
            "\n",
            "Epoch 5/40\n",
            "Training Average Loss: 0.9755\n",
            "Validation Loss: 1.1043, Validation Accuracy: 58.91%\n",
            "\n",
            "Epoch 6/40\n",
            "Training Average Loss: 0.9831\n",
            "Validation Loss: 1.1357, Validation Accuracy: 58.13%\n",
            "\n",
            "Epoch 7/40\n",
            "Training Average Loss: 0.9340\n",
            "Validation Loss: 1.1071, Validation Accuracy: 57.48%\n",
            "\n",
            "Epoch 8/40\n",
            "Training Average Loss: 0.9624\n",
            "Validation Loss: 1.1326, Validation Accuracy: 58.26%\n",
            "\n",
            "Epoch 9/40\n",
            "Training Average Loss: 1.0425\n",
            "Validation Loss: 1.2313, Validation Accuracy: 58.26%\n",
            "\n",
            "Epoch 10/40\n",
            "Training Average Loss: 0.9485\n",
            "Validation Loss: 1.1309, Validation Accuracy: 56.05%\n",
            "\n",
            "Epoch 11/40\n",
            "Training Average Loss: 0.9621\n",
            "Validation Loss: 1.1783, Validation Accuracy: 56.44%\n",
            "\n",
            "Epoch 12/40\n",
            "Training Average Loss: 0.9535\n",
            "Validation Loss: 1.1444, Validation Accuracy: 56.96%\n",
            "\n",
            "Epoch 13/40\n",
            "Training Average Loss: 0.9305\n",
            "Validation Loss: 1.1215, Validation Accuracy: 55.66%\n",
            "\n",
            "Epoch 14/40\n",
            "Training Average Loss: 1.0158\n",
            "Validation Loss: 1.1972, Validation Accuracy: 55.27%\n",
            "\n",
            "Epoch 15/40\n",
            "Training Average Loss: 1.0005\n",
            "Validation Loss: 1.1824, Validation Accuracy: 57.35%\n",
            "\n",
            "Epoch 16/40\n",
            "Training Average Loss: 0.9493\n",
            "Validation Loss: 1.1614, Validation Accuracy: 58.00%\n",
            "\n",
            "Epoch 17/40\n",
            "Training Average Loss: 0.9462\n",
            "Validation Loss: 1.1122, Validation Accuracy: 55.40%\n",
            "\n",
            "Epoch 18/40\n",
            "Training Average Loss: 0.9843\n",
            "Validation Loss: 1.1705, Validation Accuracy: 54.36%\n",
            "\n",
            "Epoch 19/40\n",
            "Training Average Loss: 0.9533\n",
            "Validation Loss: 1.1238, Validation Accuracy: 56.44%\n",
            "\n",
            "Epoch 20/40\n",
            "Training Average Loss: 0.9749\n",
            "Validation Loss: 1.1956, Validation Accuracy: 58.26%\n",
            "\n",
            "Epoch 21/40\n",
            "Training Average Loss: 0.9481\n",
            "Validation Loss: 1.2174, Validation Accuracy: 59.17%\n",
            "\n",
            "Epoch 22/40\n",
            "Training Average Loss: 0.9469\n",
            "Validation Loss: 1.1482, Validation Accuracy: 58.13%\n",
            "\n",
            "Epoch 23/40\n",
            "Training Average Loss: 1.0199\n",
            "Validation Loss: 1.1971, Validation Accuracy: 56.83%\n",
            "\n",
            "Epoch 24/40\n",
            "Training Average Loss: 0.9994\n",
            "Validation Loss: 1.1807, Validation Accuracy: 57.61%\n",
            "\n",
            "Epoch 25/40\n",
            "Training Average Loss: 0.9291\n",
            "Validation Loss: 1.1040, Validation Accuracy: 57.35%\n",
            "\n",
            "Epoch 26/40\n",
            "Training Average Loss: 0.9798\n",
            "Validation Loss: 1.1165, Validation Accuracy: 57.09%\n",
            "\n",
            "Epoch 27/40\n",
            "Training Average Loss: 0.9783\n",
            "Validation Loss: 1.1170, Validation Accuracy: 58.91%\n",
            "\n",
            "Epoch 28/40\n",
            "Training Average Loss: 0.9979\n",
            "Validation Loss: 1.1013, Validation Accuracy: 57.35%\n",
            "\n",
            "Epoch 29/40\n",
            "Training Average Loss: 0.9681\n",
            "Validation Loss: 1.1738, Validation Accuracy: 58.26%\n",
            "\n",
            "Epoch 30/40\n",
            "Training Average Loss: 0.9276\n",
            "Validation Loss: 1.1223, Validation Accuracy: 57.48%\n",
            "\n",
            "Epoch 31/40\n",
            "Training Average Loss: 0.9606\n",
            "Validation Loss: 1.1485, Validation Accuracy: 59.04%\n",
            "\n",
            "Epoch 32/40\n",
            "Training Average Loss: 0.9392\n",
            "Validation Loss: 1.1145, Validation Accuracy: 56.70%\n",
            "\n",
            "Epoch 33/40\n",
            "Training Average Loss: 0.9318\n",
            "Validation Loss: 1.1181, Validation Accuracy: 57.35%\n",
            "\n",
            "Epoch 34/40\n",
            "Training Average Loss: 0.9615\n",
            "Validation Loss: 1.1838, Validation Accuracy: 58.00%\n",
            "\n",
            "Epoch 35/40\n",
            "Training Average Loss: 0.9385\n",
            "Validation Loss: 1.1662, Validation Accuracy: 57.22%\n",
            "\n",
            "Epoch 36/40\n",
            "Training Average Loss: 0.9382\n",
            "Validation Loss: 1.1340, Validation Accuracy: 56.44%\n",
            "\n",
            "Epoch 37/40\n",
            "Training Average Loss: 1.0259\n",
            "Validation Loss: 1.1654, Validation Accuracy: 57.74%\n",
            "\n",
            "Epoch 38/40\n",
            "Training Average Loss: 0.9764\n",
            "Validation Loss: 1.1478, Validation Accuracy: 58.39%\n",
            "\n",
            "Epoch 39/40\n",
            "Training Average Loss: 0.9518\n",
            "Validation Loss: 1.1300, Validation Accuracy: 56.57%\n",
            "\n",
            "Epoch 40/40\n",
            "Training Average Loss: 0.9710\n",
            "Validation Loss: 1.1761, Validation Accuracy: 58.39%\n",
            "\n",
            "\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "\n",
            "Test Loss: 1.0407, Test Accuracy: 59.61%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(59.6078, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Psj46MKiM8rc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}